{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Run-Me.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRJI5Em6IC1R"
      },
      "source": [
        "## Cloning the Repo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V97Zn-wmzEEM",
        "outputId": "5050a76e-7901-4809-9eec-48946258de79"
      },
      "source": [
        "!git clone \"https://github.com/AslanDevbrat/Document-Ranking.git\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'Document-Ranking'...\n",
            "remote: Enumerating objects: 64, done.\u001b[K\n",
            "remote: Counting objects: 100% (64/64), done.\u001b[K\n",
            "remote: Compressing objects: 100% (50/50), done.\u001b[K\n",
            "remote: Total 64 (delta 4), reused 58 (delta 2), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (64/64), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubwG19l1IJGB"
      },
      "source": [
        "## Changing the current Directory to the Document-Ranking\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tj1ccc_l4uDw",
        "outputId": "524306a0-7db4-4a9f-db9d-916880171099"
      },
      "source": [
        "% cd Document-Ranking"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/Document-Ranking\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXAGm0-JIT7t"
      },
      "source": [
        "## Installing the Specific Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3tZTMYB49kG",
        "outputId": "e78ed935-4d70-48a5-b03f-bd5379c5df3f"
      },
      "source": [
        "!pip install allennlp==1.2.0\r\n",
        "!pip install transformers==3.1.0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting allennlp==1.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b5/14/f0f9dd1ce012e7723742821b95b33dd9bdc53befe209600608bc7be1f650/allennlp-1.2.0-py3-none-any.whl (498kB)\n",
            "\r\u001b[K     |▋                               | 10kB 22.1MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20kB 27.0MB/s eta 0:00:01\r\u001b[K     |██                              | 30kB 18.6MB/s eta 0:00:01\r\u001b[K     |██▋                             | 40kB 12.4MB/s eta 0:00:01\r\u001b[K     |███▎                            | 51kB 8.1MB/s eta 0:00:01\r\u001b[K     |████                            | 61kB 8.6MB/s eta 0:00:01\r\u001b[K     |████▋                           | 71kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 81kB 9.0MB/s eta 0:00:01\r\u001b[K     |██████                          | 92kB 9.1MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 102kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 112kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████                        | 122kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 133kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 143kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 153kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 163kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 174kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 184kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 194kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 204kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 215kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 225kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 235kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 245kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 256kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 266kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 276kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████▍             | 286kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 296kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 307kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 317kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 327kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 337kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 348kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 358kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 368kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 378kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 389kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 399kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 409kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 419kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 430kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 440kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 450kB 9.4MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 460kB 9.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 471kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 481kB 9.4MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 491kB 9.4MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 501kB 9.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (3.0.12)\n",
            "Requirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (1.7.0+cu101)\n",
            "Collecting overrides==3.1.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (3.2.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (1.4.1)\n",
            "Collecting boto3<2.0,>=1.14\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4d/cd/513fff674c22507caf5a983ac1aacf87fc207535ada17d720199b51b6cc3/boto3-1.16.36-py2.py3-none-any.whl (130kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 16.5MB/s \n",
            "\u001b[?25hCollecting tensorboardX>=1.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 16.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (4.41.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (0.22.2.post1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (0.8)\n",
            "Collecting jsonnet>=0.10.0; sys_platform != \"win32\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/42/40/6f16e5ac994b16fa71c24310f97174ce07d3a97b433275589265c6b94d2b/jsonnet-0.17.0.tar.gz (259kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 20.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (2.2.4)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (3.6.4)\n",
            "Collecting jsonpickle\n",
            "  Downloading https://files.pythonhosted.org/packages/ee/d5/1cc282dc23346a43aab461bf2e8c36593aacd34242bee1a13fa750db0cfe/jsonpickle-1.4.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp==1.2.0) (2.10.0)\n",
            "Collecting transformers<3.5,>=3.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3MB 22.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp==1.2.0) (3.7.4.3)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp==1.2.0) (0.16.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk->allennlp==1.2.0) (1.15.0)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 8.8MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Collecting botocore<1.20.0,>=1.19.36\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9c/27/f8757c8d3d11a2332677e2be978f2a524ab13d07d3766e2fff18693e6f3d/botocore-1.19.36-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1MB 30.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp==1.2.0) (3.12.4)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp==1.2.0) (0.17.0)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (7.4.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (0.8.0)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (3.0.5)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (1.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (50.3.2)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (2.0.5)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (0.4.1)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (1.0.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (1.0.5)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp==1.2.0) (1.0.5)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.2.0) (1.4.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.2.0) (1.9.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.2.0) (8.6.0)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.2.0) (0.7.1)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp==1.2.0) (20.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp==1.2.0) (3.1.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.2.0) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.2.0) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.2.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp==1.2.0) (3.0.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp==1.2.0) (20.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 55.4MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 45.0MB/s \n",
            "\u001b[?25hCollecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 51.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp==1.2.0) (2019.12.20)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.36->boto3<2.0,>=1.14->allennlp==1.2.0) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp==1.2.0) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.5,>=3.1->allennlp==1.2.0) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.5,>=3.1->allennlp==1.2.0) (7.1.2)\n",
            "Building wheels for collected packages: overrides, jsonnet, sacremoses\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp36-none-any.whl size=10175 sha256=7696928b121f2673860ada67ae54e9298448dfc5f2dc6f373e82aa008bdb9b12\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "  Building wheel for jsonnet (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jsonnet: filename=jsonnet-0.17.0-cp36-cp36m-linux_x86_64.whl size=3387917 sha256=fd9f2ad8fda5ee701bf8066f2833c7fd3736267f8dc22af8b826391e90f1a7b8\n",
            "  Stored in directory: /root/.cache/pip/wheels/26/7a/37/7dbcc30a6b4efd17b91ad1f0128b7bbf84813bd4e1cfb8c1e3\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=3c895aa22f82e9f802bda3cc53645a775bc823a47bb3e49809721250ee7ae311\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built overrides jsonnet sacremoses\n",
            "\u001b[31mERROR: botocore 1.19.36 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: overrides, jmespath, botocore, s3transfer, boto3, tensorboardX, jsonnet, jsonpickle, sacremoses, tokenizers, sentencepiece, transformers, allennlp\n",
            "Successfully installed allennlp-1.2.0 boto3-1.16.36 botocore-1.19.36 jmespath-0.10.0 jsonnet-0.17.0 jsonpickle-1.4.2 overrides-3.1.0 s3transfer-0.3.3 sacremoses-0.0.43 sentencepiece-0.1.94 tensorboardX-2.1 tokenizers-0.9.2 transformers-3.4.0\n",
            "Collecting transformers==3.1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 9.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (0.8)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (3.0.12)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 19.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (1.18.5)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (4.41.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (20.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (0.1.94)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers==3.1.0) (0.0.43)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers==3.1.0) (2.10)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers==3.1.0) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.1.0) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.1.0) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers==3.1.0) (1.15.0)\n",
            "Installing collected packages: tokenizers, transformers\n",
            "  Found existing installation: tokenizers 0.9.2\n",
            "    Uninstalling tokenizers-0.9.2:\n",
            "      Successfully uninstalled tokenizers-0.9.2\n",
            "  Found existing installation: transformers 3.4.0\n",
            "    Uninstalling transformers-3.4.0:\n",
            "      Successfully uninstalled transformers-3.4.0\n",
            "Successfully installed tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z50UypvJIadk"
      },
      "source": [
        "## Downloading and Spliting the Data-set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "wyrsLoTA5KM2",
        "outputId": "cbf2cf55-5ed0-480f-a5af-be5e762e22f8"
      },
      "source": [
        "!python scripts/data_split.py \"https://github.com/microsoft/MIMICS/raw/master/data/MIMICS-ClickExplore.tsv\" "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading: 23153608B [00:00, 136682036.93B/s]\n",
            "Saving to /tmp/allenrank/data/mimics-clickexplore.\n",
            "/tmp/allenrank/data/mimics-clickexplore/train.tsv: (94595, 14)\n",
            "/tmp/allenrank/data/mimics-clickexplore/valid.tsv: (23649, 14)\n",
            "/tmp/allenrank/data/mimics-clickexplore/test.tsv: (50677, 14)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1q2OAjKfIhvY"
      },
      "source": [
        "## Installing the other required Libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t_QRqbCv5PaC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fe744126-f99d-4204-fd8f-cfcfeba04778"
      },
      "source": [
        "pip install -r requirements.txt\r\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: allennlp in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: allennlp-models in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 2)) (1.2.2)\n",
            "Requirement already satisfied: torchsnooper in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 3)) (0.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 5)) (1.1.5)\n",
            "Requirement already satisfied: pytest-pythonpath in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 7)) (0.7.3)\n",
            "Requirement already satisfied: pylint==1.8.1 in /usr/local/lib/python3.6/dist-packages (from -r requirements.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (3.2.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (0.8)\n",
            "Requirement already satisfied: requests>=2.18 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (2.23.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (2.10.0)\n",
            "Requirement already satisfied: pytest in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (3.6.4)\n",
            "Requirement already satisfied: jsonpickle in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (1.4.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (0.22.2.post1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (1.18.5)\n",
            "Requirement already satisfied: jsonnet>=0.10.0; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: overrides==3.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: spacy<2.4,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (2.2.4)\n",
            "Requirement already satisfied: tensorboardX>=1.2 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (2.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (1.4.1)\n",
            "Requirement already satisfied: filelock<3.1,>=3.0 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.19 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (4.41.1)\n",
            "Requirement already satisfied: torch<1.8.0,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (1.7.0+cu101)\n",
            "Requirement already satisfied: boto3<2.0,>=1.14 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (1.16.36)\n",
            "Requirement already satisfied: transformers<3.5,>=3.1 in /usr/local/lib/python3.6/dist-packages (from allennlp->-r requirements.txt (line 1)) (3.1.0)\n",
            "Requirement already satisfied: ftfy in /usr/local/lib/python3.6/dist-packages (from allennlp-models->-r requirements.txt (line 2)) (5.8)\n",
            "Requirement already satisfied: conllu==4.2.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models->-r requirements.txt (line 2)) (4.2.1)\n",
            "Requirement already satisfied: py-rouge==1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models->-r requirements.txt (line 2)) (1.1)\n",
            "Requirement already satisfied: word2number>=1.1 in /usr/local/lib/python3.6/dist-packages (from allennlp-models->-r requirements.txt (line 2)) (1.1)\n",
            "Requirement already satisfied: pysnooper>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from torchsnooper->-r requirements.txt (line 3)) (0.4.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->-r requirements.txt (line 5)) (2.8.1)\n",
            "Requirement already satisfied: isort>=4.2.5 in /usr/local/lib/python3.6/dist-packages (from pylint==1.8.1->-r requirements.txt (line 10)) (5.6.4)\n",
            "Requirement already satisfied: astroid<2.0 in /usr/local/lib/python3.6/dist-packages (from pylint==1.8.1->-r requirements.txt (line 10)) (1.6.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from pylint==1.8.1->-r requirements.txt (line 10)) (1.15.0)\n",
            "Requirement already satisfied: mccabe in /usr/local/lib/python3.6/dist-packages (from pylint==1.8.1->-r requirements.txt (line 10)) (0.6.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 1)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 1)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 1)) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.18->allennlp->-r requirements.txt (line 1)) (3.0.4)\n",
            "Requirement already satisfied: pluggy<0.8,>=0.5 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 1)) (0.7.1)\n",
            "Requirement already satisfied: atomicwrites>=1.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 1)) (1.4.0)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 1)) (8.6.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 1)) (50.3.2)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.6/dist-packages (from pytest->allennlp->-r requirements.txt (line 1)) (20.3.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from jsonpickle->allennlp->-r requirements.txt (line 1)) (3.1.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->allennlp->-r requirements.txt (line 1)) (0.17.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (0.8.0)\n",
            "Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (1.0.0)\n",
            "Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (1.1.3)\n",
            "Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (0.4.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (3.0.5)\n",
            "Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (7.4.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (1.0.5)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from spacy<2.4,>=2.1.0->allennlp->-r requirements.txt (line 1)) (2.0.5)\n",
            "Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from tensorboardX>=1.2->allennlp->-r requirements.txt (line 1)) (3.12.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch<1.8.0,>=1.6.0->allennlp->-r requirements.txt (line 1)) (3.7.4.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3<2.0,>=1.14->allennlp->-r requirements.txt (line 1)) (0.10.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3<2.0,>=1.14->allennlp->-r requirements.txt (line 1)) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.20.0,>=1.19.36 in /usr/local/lib/python3.6/dist-packages (from boto3<2.0,>=1.14->allennlp->-r requirements.txt (line 1)) (1.19.36)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (20.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (0.0.43)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (0.8.1rc2)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (0.1.94)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from ftfy->allennlp-models->-r requirements.txt (line 2)) (0.2.5)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.6/dist-packages (from astroid<2.0->pylint==1.8.1->-r requirements.txt (line 10)) (1.12.1)\n",
            "Requirement already satisfied: lazy-object-proxy in /usr/local/lib/python3.6/dist-packages (from astroid<2.0->pylint==1.8.1->-r requirements.txt (line 10)) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->jsonpickle->allennlp->-r requirements.txt (line 1)) (3.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers<3.5,>=3.1->allennlp->-r requirements.txt (line 1)) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hM1QTMvRIrdL"
      },
      "source": [
        "## Training and evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o43a173C5RQL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86f4fe6c-770b-4d9d-c0d5-f2adbf6636fa"
      },
      "source": [
        "!allennlp train experiments/mimics.jsonnet -s result2"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2020-12-15 10:52:17.989741: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcudart.so.10.1\n",
            "2020-12-15 10:52:20,297 - INFO - allennlp.common.plugins - Plugin allennlp_models available\n",
            "2020-12-15 10:52:20,305 - INFO - allennlp.common.plugins - Plugin allenrank available\n",
            "2020-12-15 10:52:20,338 - INFO - allennlp.common.params - include_in_archive = None\n",
            "2020-12-15 10:52:20,338 - INFO - allennlp.common.params - random_seed = 13370\n",
            "2020-12-15 10:52:20,338 - INFO - allennlp.common.params - numpy_seed = 1337\n",
            "2020-12-15 10:52:20,338 - INFO - allennlp.common.params - pytorch_seed = 133\n",
            "2020-12-15 10:52:20,382 - INFO - allennlp.common.checks - Pytorch version: 1.7.0+cu101\n",
            "2020-12-15 10:52:20,383 - INFO - allennlp.common.params - type = default\n",
            "2020-12-15 10:52:20,385 - INFO - allennlp.common.params - dataset_reader.type = mimics\n",
            "2020-12-15 10:52:20,386 - INFO - allennlp.common.params - dataset_reader.lazy = False\n",
            "2020-12-15 10:52:20,386 - INFO - allennlp.common.params - dataset_reader.cache_directory = None\n",
            "2020-12-15 10:52:20,386 - INFO - allennlp.common.params - dataset_reader.max_instances = 50000\n",
            "2020-12-15 10:52:20,386 - INFO - allennlp.common.params - dataset_reader.manual_distributed_sharding = False\n",
            "2020-12-15 10:52:20,386 - INFO - allennlp.common.params - dataset_reader.manual_multi_process_sharding = False\n",
            "2020-12-15 10:52:20,386 - INFO - allennlp.common.params - dataset_reader.tokenizer.type = pretrained_transformer\n",
            "2020-12-15 10:52:20,387 - INFO - allennlp.common.params - dataset_reader.tokenizer.model_name = google/bert_uncased_L-2_H-128_A-2\n",
            "2020-12-15 10:52:20,387 - INFO - allennlp.common.params - dataset_reader.tokenizer.add_special_tokens = True\n",
            "2020-12-15 10:52:20,387 - INFO - allennlp.common.params - dataset_reader.tokenizer.max_length = None\n",
            "2020-12-15 10:52:20,387 - INFO - allennlp.common.params - dataset_reader.tokenizer.stride = 0\n",
            "2020-12-15 10:52:20,387 - INFO - allennlp.common.params - dataset_reader.tokenizer.tokenizer_kwargs = None\n",
            "2020-12-15 10:52:23,942 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.type = pretrained_transformer\n",
            "2020-12-15 10:52:23,943 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.token_min_padding_length = 0\n",
            "2020-12-15 10:52:23,943 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.model_name = google/bert_uncased_L-2_H-128_A-2\n",
            "2020-12-15 10:52:23,943 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.namespace = tags\n",
            "2020-12-15 10:52:23,943 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.max_length = None\n",
            "2020-12-15 10:52:23,943 - INFO - allennlp.common.params - dataset_reader.token_indexers.tokens.tokenizer_kwargs = None\n",
            "2020-12-15 10:52:23,943 - INFO - allennlp.common.params - dataset_reader.max_tokens = None\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - train_data_path = /tmp/allenrank/data/mimics-clickexplore/train.tsv\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - vocabulary = <allennlp.common.lazy.Lazy object at 0x7f5d57c7c2e8>\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - datasets_for_vocab_creation = None\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - validation_dataset_reader = None\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - validation_data_path = /tmp/allenrank/data/mimics-clickexplore/valid.tsv\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - validation_data_loader = None\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - test_data_path = None\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - evaluate_on_test = False\n",
            "2020-12-15 10:52:23,944 - INFO - allennlp.common.params - batch_weight_key = \n",
            "2020-12-15 10:52:23,945 - INFO - allennlp.training.util - Reading training data from /tmp/allenrank/data/mimics-clickexplore/train.tsv\n",
            "reading instances: 0it [00:00, ?it/s]2020-12-15 10:52:23,945 - INFO - allenrank.dataset_readers.mimics_reader - Reading instances from lines in file at: /tmp/allenrank/data/mimics-clickexplore/train.tsv\n",
            "reading instances: 50000it [00:23, 2086.68it/s]\n",
            "2020-12-15 10:52:47,907 - INFO - allennlp.training.util - Reading validation data from /tmp/allenrank/data/mimics-clickexplore/valid.tsv\n",
            "reading instances: 0it [00:00, ?it/s]2020-12-15 10:52:47,907 - INFO - allenrank.dataset_readers.mimics_reader - Reading instances from lines in file at: /tmp/allenrank/data/mimics-clickexplore/valid.tsv\n",
            "reading instances: 23649it [00:11, 2000.72it/s]\n",
            "2020-12-15 10:52:59,728 - INFO - allennlp.common.params - type = from_instances\n",
            "2020-12-15 10:52:59,728 - INFO - allennlp.common.params - min_count = None\n",
            "2020-12-15 10:52:59,728 - INFO - allennlp.common.params - max_vocab_size = None\n",
            "2020-12-15 10:52:59,728 - INFO - allennlp.common.params - non_padded_namespaces = ('*tags', '*labels')\n",
            "2020-12-15 10:52:59,728 - INFO - allennlp.common.params - pretrained_files = None\n",
            "2020-12-15 10:52:59,729 - INFO - allennlp.common.params - only_include_pretrained_words = False\n",
            "2020-12-15 10:52:59,729 - INFO - allennlp.common.params - tokens_to_add = None\n",
            "2020-12-15 10:52:59,729 - INFO - allennlp.common.params - min_pretrained_embeddings = None\n",
            "2020-12-15 10:52:59,729 - INFO - allennlp.common.params - padding_token = @@PADDING@@\n",
            "2020-12-15 10:52:59,729 - INFO - allennlp.common.params - oov_token = @@UNKNOWN@@\n",
            "2020-12-15 10:52:59,729 - INFO - allennlp.data.vocabulary - Fitting token dictionary from dataset.\n",
            "building vocab: 73649it [00:00, 152581.28it/s]\n",
            "2020-12-15 10:53:00,212 - INFO - allennlp.common.params - model.type = ranker\n",
            "2020-12-15 10:53:00,213 - INFO - allennlp.common.params - model.regularizer = None\n",
            "2020-12-15 10:53:00,213 - INFO - allennlp.common.params - model.text_field_embedder.type = basic\n",
            "2020-12-15 10:53:00,213 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.type = pretrained_transformer\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.model_name = google/bert_uncased_L-2_H-128_A-2\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.max_length = None\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.sub_module = None\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.train_parameters = True\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.last_layer_only = True\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_file = None\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.override_weights_strip_prefix = None\n",
            "2020-12-15 10:53:00,214 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.gradient_checkpointing = None\n",
            "2020-12-15 10:53:00,215 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.tokenizer_kwargs = None\n",
            "2020-12-15 10:53:00,215 - INFO - allennlp.common.params - model.text_field_embedder.token_embedders.tokens.transformer_kwargs = None\n",
            "2020-12-15 10:53:00,885 - INFO - allennlp.common.params - model.relevance_matcher.type = bert_cls\n",
            "2020-12-15 10:53:00,886 - INFO - allennlp.common.params - model.relevance_matcher.input_dim = 128\n",
            "2020-12-15 10:53:00,886 - INFO - allennlp.common.params - model.dropout = 0.35\n",
            "2020-12-15 10:53:00,886 - INFO - allennlp.common.params - model.num_labels = None\n",
            "2020-12-15 10:53:00,886 - INFO - allennlp.common.params - model.initializer = <allennlp.nn.initializers.InitializerApplicator object at 0x7f5d57b7d828>\n",
            "2020-12-15 10:53:00,887 - INFO - allennlp.nn.initializers - Initializing parameters\n",
            "2020-12-15 10:53:00,887 - INFO - allennlp.nn.initializers - Done initializing parameters; the following parameters are using their default initialization from their code\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _relevance_matcher._module.dense.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2020-12-15 10:53:00,888 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2020-12-15 10:53:00,889 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\n",
            "2020-12-15 10:53:00,890 - INFO - allennlp.nn.initializers -    _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.batch_size = 256\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.sampler = None\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2020-12-15 10:53:00,891 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2020-12-15 10:53:00,892 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2020-12-15 10:53:00,892 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2020-12-15 10:53:00,892 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2020-12-15 10:53:00,892 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2020-12-15 10:53:00,892 - INFO - allennlp.common.params - data_loader.type = pytorch_dataloader\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.batch_size = 256\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.shuffle = False\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.sampler = None\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.batch_sampler = None\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.num_workers = 0\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.pin_memory = False\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.drop_last = False\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.timeout = 0\n",
            "2020-12-15 10:53:00,893 - INFO - allennlp.common.params - data_loader.worker_init_fn = None\n",
            "2020-12-15 10:53:00,894 - INFO - allennlp.common.params - data_loader.multiprocessing_context = None\n",
            "2020-12-15 10:53:00,894 - INFO - allennlp.common.params - data_loader.batches_per_epoch = None\n",
            "2020-12-15 10:53:00,894 - INFO - allennlp.common.params - trainer.type = gradient_descent\n",
            "2020-12-15 10:53:00,894 - INFO - allennlp.common.params - trainer.patience = None\n",
            "2020-12-15 10:53:00,894 - INFO - allennlp.common.params - trainer.validation_metric = +auc\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.num_epochs = 20\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.cuda_device = 0\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.grad_norm = None\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.grad_clipping = None\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.distributed = False\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.world_size = 1\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.num_gradient_accumulation_steps = 1\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.use_amp = False\n",
            "2020-12-15 10:53:00,895 - INFO - allennlp.common.params - trainer.no_grad = None\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.momentum_scheduler = None\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.tensorboard_writer = <allennlp.common.lazy.Lazy object at 0x7f5d57c4ec18>\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.moving_average = None\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.checkpointer = <allennlp.common.lazy.Lazy object at 0x7f5d57c4ee48>\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.batch_callbacks = None\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.epoch_callbacks = None\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.end_callbacks = None\n",
            "2020-12-15 10:53:00,896 - INFO - allennlp.common.params - trainer.trainer_callbacks = None\n",
            "2020-12-15 10:53:05,309 - INFO - allennlp.common.params - trainer.optimizer.type = adam\n",
            "2020-12-15 10:53:05,309 - INFO - allennlp.common.params - trainer.optimizer.parameter_groups = None\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.common.params - trainer.optimizer.lr = 0.0001\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.common.params - trainer.optimizer.betas = (0.9, 0.999)\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.common.params - trainer.optimizer.eps = 1e-08\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.common.params - trainer.optimizer.weight_decay = 0.0\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.common.params - trainer.optimizer.amsgrad = False\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.training.optimizers - Number of trainable parameters: 4386432\n",
            "2020-12-15 10:53:05,310 - INFO - allennlp.common.util - The following parameters are Frozen (without gradient):\n",
            "2020-12-15 10:53:05,311 - INFO - allennlp.common.util - The following parameters are Tunable (with gradient):\n",
            "2020-12-15 10:53:05,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.word_embeddings.weight\n",
            "2020-12-15 10:53:05,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.position_embeddings.weight\n",
            "2020-12-15 10:53:05,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.token_type_embeddings.weight\n",
            "2020-12-15 10:53:05,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.weight\n",
            "2020-12-15 10:53:05,311 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.embeddings.LayerNorm.bias\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.weight\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.query.bias\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.weight\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.key.bias\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.weight\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.self.value.bias\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.weight\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.dense.bias\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.weight\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.attention.output.LayerNorm.bias\n",
            "2020-12-15 10:53:05,312 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.weight\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.intermediate.dense.bias\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.weight\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.dense.bias\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.weight\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.0.output.LayerNorm.bias\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.weight\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.query.bias\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.weight\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.key.bias\n",
            "2020-12-15 10:53:05,313 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.weight\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.self.value.bias\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.weight\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.dense.bias\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.weight\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.attention.output.LayerNorm.bias\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.weight\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.intermediate.dense.bias\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.weight\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.dense.bias\n",
            "2020-12-15 10:53:05,314 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.weight\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.encoder.layer.1.output.LayerNorm.bias\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.weight\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.util - _text_field_embedder.token_embedder_tokens.transformer_model.pooler.dense.bias\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.util - _relevance_matcher._module.dense.weight\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.type = reduce_on_plateau\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.mode = max\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.factor = 0.5\n",
            "2020-12-15 10:53:05,315 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.patience = 0\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.verbose = False\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold_mode = rel\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.threshold = 0.0001\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.cooldown = 0\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.min_lr = 0\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - trainer.learning_rate_scheduler.eps = 1e-08\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - type = default\n",
            "2020-12-15 10:53:05,316 - INFO - allennlp.common.params - keep_serialized_model_every_num_seconds = None\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - num_serialized_models_to_keep = 2\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - model_save_interval = None\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - summary_interval = 100\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - histogram_interval = None\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - batch_size_interval = None\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - should_log_parameter_statistics = True\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - should_log_learning_rate = False\n",
            "2020-12-15 10:53:05,317 - INFO - allennlp.common.params - get_batch_num_total = None\n",
            "2020-12-15 10:53:05,319 - WARNING - allennlp.training.trainer - You provided a validation dataset but patience was set to None, meaning that early stopping is disabled\n",
            "2020-12-15 10:53:05,320 - INFO - allennlp.training.trainer - Beginning training.\n",
            "2020-12-15 10:53:05,320 - INFO - allennlp.training.trainer - Epoch 0/19\n",
            "2020-12-15 10:53:05,320 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.4G\n",
            "2020-12-15 10:53:05,320 - INFO - allennlp.training.trainer - GPU 0 memory usage: 17M\n",
            "2020-12-15 10:53:05,320 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.5365, mrr: 0.8014, ndcg: 0.3890, batch_loss: 0.1024, loss: 0.1149 ||: 100%|##########| 196/196 [00:38<00:00,  5.14it/s]\n",
            "2020-12-15 10:53:43,600 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6105, mrr: 0.8310, ndcg: 0.4095, batch_loss: 0.1168, loss: 0.1103 ||: 100%|##########| 93/93 [00:11<00:00,  8.37it/s]\n",
            "2020-12-15 10:53:54,759 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:53:54,760 - INFO - allennlp.training.tensorboard_writer - auc                |     0.537  |     0.611\n",
            "2020-12-15 10:53:54,761 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |    16.737  |       N/A\n",
            "2020-12-15 10:53:54,761 - INFO - allennlp.training.tensorboard_writer - loss               |     0.115  |     0.110\n",
            "2020-12-15 10:53:54,762 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.801  |     0.831\n",
            "2020-12-15 10:53:54,763 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.389  |     0.409\n",
            "2020-12-15 10:53:54,763 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4527.879  |       N/A\n",
            "2020-12-15 10:53:54,848 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'result2/best.th'.\n",
            "2020-12-15 10:53:54,866 - INFO - allennlp.training.trainer - Epoch duration: 0:00:49.546573\n",
            "2020-12-15 10:53:54,867 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:15:41\n",
            "2020-12-15 10:53:54,868 - INFO - allennlp.training.trainer - Epoch 1/19\n",
            "2020-12-15 10:53:54,868 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:53:54,868 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:53:54,868 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.6074, mrr: 0.8263, ndcg: 0.4068, batch_loss: 0.0965, loss: 0.1091 ||: 100%|##########| 196/196 [00:37<00:00,  5.22it/s]\n",
            "2020-12-15 10:54:32,577 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6420, mrr: 0.8410, ndcg: 0.4166, batch_loss: 0.1157, loss: 0.1086 ||: 100%|##########| 93/93 [00:10<00:00,  8.59it/s]\n",
            "2020-12-15 10:54:43,453 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:54:43,453 - INFO - allennlp.training.tensorboard_writer - auc                |     0.607  |     0.642\n",
            "2020-12-15 10:54:43,454 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:54:43,455 - INFO - allennlp.training.tensorboard_writer - loss               |     0.109  |     0.109\n",
            "2020-12-15 10:54:43,456 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.826  |     0.841\n",
            "2020-12-15 10:54:43,457 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.407  |     0.417\n",
            "2020-12-15 10:54:43,457 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4872.035  |       N/A\n",
            "2020-12-15 10:54:43,537 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'result2/best.th'.\n",
            "2020-12-15 10:54:43,568 - INFO - allennlp.training.trainer - Epoch duration: 0:00:48.699938\n",
            "2020-12-15 10:54:43,568 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:14:44\n",
            "2020-12-15 10:54:43,568 - INFO - allennlp.training.trainer - Epoch 2/19\n",
            "2020-12-15 10:54:43,568 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:54:43,569 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:54:43,569 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.6363, mrr: 0.8354, ndcg: 0.4133, batch_loss: 0.0948, loss: 0.1075 ||: 100%|##########| 196/196 [00:35<00:00,  5.47it/s]\n",
            "2020-12-15 10:55:19,544 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6514, mrr: 0.8432, ndcg: 0.4184, batch_loss: 0.1168, loss: 0.1079 ||: 100%|##########| 93/93 [00:10<00:00,  8.61it/s]\n",
            "2020-12-15 10:55:30,392 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:55:30,392 - INFO - allennlp.training.tensorboard_writer - auc                |     0.636  |     0.651\n",
            "2020-12-15 10:55:30,393 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:55:30,394 - INFO - allennlp.training.tensorboard_writer - loss               |     0.108  |     0.108\n",
            "2020-12-15 10:55:30,395 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.835  |     0.843\n",
            "2020-12-15 10:55:30,395 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.413  |     0.418\n",
            "2020-12-15 10:55:30,396 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4875.121  |       N/A\n",
            "2020-12-15 10:55:30,474 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'result2/best.th'.\n",
            "2020-12-15 10:55:30,500 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.932091\n",
            "2020-12-15 10:55:30,500 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:13:42\n",
            "2020-12-15 10:55:30,500 - INFO - allennlp.training.trainer - Epoch 3/19\n",
            "2020-12-15 10:55:30,500 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:55:30,501 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:55:30,501 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.6566, mrr: 0.8439, ndcg: 0.4195, batch_loss: 0.0897, loss: 0.1063 ||: 100%|##########| 196/196 [00:35<00:00,  5.49it/s]\n",
            "2020-12-15 10:56:06,350 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6547, mrr: 0.8444, ndcg: 0.4192, batch_loss: 0.1185, loss: 0.1082 ||: 100%|##########| 93/93 [00:10<00:00,  8.89it/s]\n",
            "2020-12-15 10:56:16,856 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:56:16,856 - INFO - allennlp.training.tensorboard_writer - auc                |     0.657  |     0.655\n",
            "2020-12-15 10:56:16,857 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:56:16,858 - INFO - allennlp.training.tensorboard_writer - loss               |     0.106  |     0.108\n",
            "2020-12-15 10:56:16,858 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.844  |     0.844\n",
            "2020-12-15 10:56:16,859 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.419  |     0.419\n",
            "2020-12-15 10:56:16,861 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4877.164  |       N/A\n",
            "2020-12-15 10:56:16,943 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'result2/best.th'.\n",
            "2020-12-15 10:56:16,968 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.467637\n",
            "2020-12-15 10:56:16,968 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:12:46\n",
            "2020-12-15 10:56:16,968 - INFO - allennlp.training.trainer - Epoch 4/19\n",
            "2020-12-15 10:56:16,968 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:56:16,969 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:56:16,969 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.6710, mrr: 0.8480, ndcg: 0.4226, batch_loss: 0.0892, loss: 0.1051 ||: 100%|##########| 196/196 [00:34<00:00,  5.67it/s]\n",
            "2020-12-15 10:56:51,676 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6555, mrr: 0.8462, ndcg: 0.4206, batch_loss: 0.1202, loss: 0.1088 ||: 100%|##########| 93/93 [00:10<00:00,  8.68it/s]\n",
            "2020-12-15 10:57:02,430 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:57:02,431 - INFO - allennlp.training.tensorboard_writer - auc                |     0.671  |     0.655\n",
            "2020-12-15 10:57:02,432 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:57:02,432 - INFO - allennlp.training.tensorboard_writer - loss               |     0.105  |     0.109\n",
            "2020-12-15 10:57:02,433 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.848  |     0.846\n",
            "2020-12-15 10:57:02,434 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.423  |     0.421\n",
            "2020-12-15 10:57:02,435 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4881.211  |       N/A\n",
            "2020-12-15 10:57:02,514 - INFO - allennlp.training.checkpointer - Best validation performance so far. Copying weights to 'result2/best.th'.\n",
            "2020-12-15 10:57:02,538 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.569424\n",
            "2020-12-15 10:57:02,538 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:11:51\n",
            "2020-12-15 10:57:02,538 - INFO - allennlp.training.trainer - Epoch 5/19\n",
            "2020-12-15 10:57:02,538 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:57:02,539 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:57:02,539 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.6838, mrr: 0.8533, ndcg: 0.4263, batch_loss: 0.0883, loss: 0.1041 ||: 100%|##########| 196/196 [00:34<00:00,  5.67it/s]\n",
            "2020-12-15 10:57:37,270 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6544, mrr: 0.8471, ndcg: 0.4212, batch_loss: 0.1218, loss: 0.1090 ||: 100%|##########| 93/93 [00:10<00:00,  8.74it/s]\n",
            "2020-12-15 10:57:47,955 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:57:47,956 - INFO - allennlp.training.tensorboard_writer - auc                |     0.684  |     0.654\n",
            "2020-12-15 10:57:47,956 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:57:47,957 - INFO - allennlp.training.tensorboard_writer - loss               |     0.104  |     0.109\n",
            "2020-12-15 10:57:47,958 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.853  |     0.847\n",
            "2020-12-15 10:57:47,958 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.426  |     0.421\n",
            "2020-12-15 10:57:47,959 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.016  |       N/A\n",
            "2020-12-15 10:57:48,043 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.504724\n",
            "2020-12-15 10:57:48,043 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:59\n",
            "2020-12-15 10:57:48,043 - INFO - allennlp.training.trainer - Epoch 6/19\n",
            "2020-12-15 10:57:48,043 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:57:48,044 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:57:48,044 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.6965, mrr: 0.8577, ndcg: 0.4295, batch_loss: 0.0845, loss: 0.1028 ||: 100%|##########| 196/196 [00:35<00:00,  5.57it/s]\n",
            "2020-12-15 10:58:23,358 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6524, mrr: 0.8467, ndcg: 0.4208, batch_loss: 0.1232, loss: 0.1099 ||: 100%|##########| 93/93 [00:10<00:00,  8.62it/s]\n",
            "2020-12-15 10:58:34,190 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:58:34,191 - INFO - allennlp.training.tensorboard_writer - auc                |     0.697  |     0.652\n",
            "2020-12-15 10:58:34,192 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:58:34,192 - INFO - allennlp.training.tensorboard_writer - loss               |     0.103  |     0.110\n",
            "2020-12-15 10:58:34,193 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.858  |     0.847\n",
            "2020-12-15 10:58:34,194 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.430  |     0.421\n",
            "2020-12-15 10:58:34,195 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.371  |       N/A\n",
            "2020-12-15 10:58:34,280 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.236518\n",
            "2020-12-15 10:58:34,280 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:10:10\n",
            "2020-12-15 10:58:34,280 - INFO - allennlp.training.trainer - Epoch 7/19\n",
            "2020-12-15 10:58:34,280 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:58:34,281 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:58:34,281 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7028, mrr: 0.8586, ndcg: 0.4303, batch_loss: 0.0835, loss: 0.1021 ||: 100%|##########| 196/196 [00:37<00:00,  5.28it/s]\n",
            "2020-12-15 10:59:11,525 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6514, mrr: 0.8468, ndcg: 0.4209, batch_loss: 0.1242, loss: 0.1108 ||: 100%|##########| 93/93 [00:10<00:00,  8.81it/s]\n",
            "2020-12-15 10:59:22,124 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 10:59:22,124 - INFO - allennlp.training.tensorboard_writer - auc                |     0.703  |     0.651\n",
            "2020-12-15 10:59:22,125 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 10:59:22,126 - INFO - allennlp.training.tensorboard_writer - loss               |     0.102  |     0.111\n",
            "2020-12-15 10:59:22,127 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.859  |     0.847\n",
            "2020-12-15 10:59:22,128 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.430  |     0.421\n",
            "2020-12-15 10:59:22,128 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.371  |       N/A\n",
            "2020-12-15 10:59:22,209 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.928747\n",
            "2020-12-15 10:59:22,209 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:09:25\n",
            "2020-12-15 10:59:22,209 - INFO - allennlp.training.trainer - Epoch 8/19\n",
            "2020-12-15 10:59:22,209 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 10:59:22,210 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 10:59:22,210 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7072, mrr: 0.8607, ndcg: 0.4317, batch_loss: 0.0844, loss: 0.1016 ||: 100%|##########| 196/196 [00:34<00:00,  5.60it/s]\n",
            "2020-12-15 10:59:57,323 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6508, mrr: 0.8467, ndcg: 0.4209, batch_loss: 0.1246, loss: 0.1109 ||: 100%|##########| 93/93 [00:10<00:00,  8.75it/s]\n",
            "2020-12-15 11:00:07,995 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:00:07,996 - INFO - allennlp.training.tensorboard_writer - auc                |     0.707  |     0.651\n",
            "2020-12-15 11:00:07,996 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:00:07,997 - INFO - allennlp.training.tensorboard_writer - loss               |     0.102  |     0.111\n",
            "2020-12-15 11:00:07,998 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.861  |     0.847\n",
            "2020-12-15 11:00:07,999 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:00:07,999 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:00:08,087 - INFO - allennlp.training.trainer - Epoch duration: 0:00:45.877794\n",
            "2020-12-15 11:00:08,087 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:08:36\n",
            "2020-12-15 11:00:08,087 - INFO - allennlp.training.trainer - Epoch 9/19\n",
            "2020-12-15 11:00:08,088 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:00:08,088 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:00:08,088 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7074, mrr: 0.8610, ndcg: 0.4318, batch_loss: 0.0833, loss: 0.1015 ||: 100%|##########| 196/196 [00:35<00:00,  5.51it/s]\n",
            "2020-12-15 11:00:43,818 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6505, mrr: 0.8466, ndcg: 0.4208, batch_loss: 0.1242, loss: 0.1105 ||: 100%|##########| 93/93 [00:11<00:00,  8.40it/s]\n",
            "2020-12-15 11:00:54,932 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:00:54,932 - INFO - allennlp.training.tensorboard_writer - auc                |     0.707  |     0.650\n",
            "2020-12-15 11:00:54,933 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:00:54,934 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:00:54,935 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.861  |     0.847\n",
            "2020-12-15 11:00:54,935 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:00:54,936 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:00:55,021 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.933115\n",
            "2020-12-15 11:00:55,021 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:49\n",
            "2020-12-15 11:00:55,021 - INFO - allennlp.training.trainer - Epoch 10/19\n",
            "2020-12-15 11:00:55,021 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:00:55,021 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:00:55,022 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7088, mrr: 0.8605, ndcg: 0.4316, batch_loss: 0.0833, loss: 0.1013 ||: 100%|##########| 196/196 [00:35<00:00,  5.52it/s]\n",
            "2020-12-15 11:01:30,667 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6504, mrr: 0.8463, ndcg: 0.4206, batch_loss: 0.1243, loss: 0.1106 ||: 100%|##########| 93/93 [00:10<00:00,  8.65it/s]\n",
            "2020-12-15 11:01:41,461 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:01:41,461 - INFO - allennlp.training.tensorboard_writer - auc                |     0.709  |     0.650\n",
            "2020-12-15 11:01:41,462 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:01:41,462 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:01:41,463 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.860  |     0.846\n",
            "2020-12-15 11:01:41,464 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:01:41,465 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:01:41,549 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.527639\n",
            "2020-12-15 11:01:41,549 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:07:02\n",
            "2020-12-15 11:01:41,549 - INFO - allennlp.training.trainer - Epoch 11/19\n",
            "2020-12-15 11:01:41,549 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:01:41,549 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:01:41,550 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7112, mrr: 0.8618, ndcg: 0.4326, batch_loss: 0.0846, loss: 0.1013 ||: 100%|##########| 196/196 [00:35<00:00,  5.54it/s]\n",
            "2020-12-15 11:02:17,041 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6503, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1106 ||: 100%|##########| 93/93 [00:10<00:00,  8.56it/s]\n",
            "2020-12-15 11:02:27,956 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:02:27,957 - INFO - allennlp.training.tensorboard_writer - auc                |     0.711  |     0.650\n",
            "2020-12-15 11:02:27,958 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:02:27,958 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:02:27,959 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.862  |     0.846\n",
            "2020-12-15 11:02:27,960 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.433  |     0.420\n",
            "2020-12-15 11:02:27,960 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:02:28,045 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.496034\n",
            "2020-12-15 11:02:28,045 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:06:15\n",
            "2020-12-15 11:02:28,045 - INFO - allennlp.training.trainer - Epoch 12/19\n",
            "2020-12-15 11:02:28,045 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:02:28,046 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:02:28,046 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7103, mrr: 0.8615, ndcg: 0.4323, batch_loss: 0.0804, loss: 0.1012 ||: 100%|##########| 196/196 [00:35<00:00,  5.59it/s]\n",
            "2020-12-15 11:03:03,243 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8463, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:10<00:00,  8.68it/s]\n",
            "2020-12-15 11:03:14,008 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:03:14,008 - INFO - allennlp.training.tensorboard_writer - auc                |     0.710  |     0.650\n",
            "2020-12-15 11:03:14,009 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:03:14,010 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:03:14,011 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.862  |     0.846\n",
            "2020-12-15 11:03:14,011 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:03:14,012 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:03:14,093 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.047531\n",
            "2020-12-15 11:03:14,093 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:05:27\n",
            "2020-12-15 11:03:14,093 - INFO - allennlp.training.trainer - Epoch 13/19\n",
            "2020-12-15 11:03:14,093 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:03:14,094 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:03:14,094 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7104, mrr: 0.8609, ndcg: 0.4320, batch_loss: 0.0849, loss: 0.1012 ||: 100%|##########| 196/196 [00:35<00:00,  5.48it/s]\n",
            "2020-12-15 11:03:50,005 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:10<00:00,  8.58it/s]\n",
            "2020-12-15 11:04:00,888 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:04:00,889 - INFO - allennlp.training.tensorboard_writer - auc                |     0.710  |     0.650\n",
            "2020-12-15 11:04:00,890 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:04:00,891 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:04:00,891 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.861  |     0.846\n",
            "2020-12-15 11:04:00,892 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:04:00,893 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:04:00,979 - INFO - allennlp.training.trainer - Epoch duration: 0:00:46.885959\n",
            "2020-12-15 11:04:00,979 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:04:40\n",
            "2020-12-15 11:04:00,980 - INFO - allennlp.training.trainer - Epoch 14/19\n",
            "2020-12-15 11:04:00,980 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:04:00,980 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:04:00,980 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7106, mrr: 0.8618, ndcg: 0.4325, batch_loss: 0.0845, loss: 0.1012 ||: 100%|##########| 196/196 [00:37<00:00,  5.23it/s]\n",
            "2020-12-15 11:04:38,594 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:10<00:00,  8.69it/s]\n",
            "2020-12-15 11:04:49,343 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:04:49,343 - INFO - allennlp.training.tensorboard_writer - auc                |     0.711  |     0.650\n",
            "2020-12-15 11:04:49,344 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:04:49,345 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:04:49,346 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.862  |     0.846\n",
            "2020-12-15 11:04:49,346 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:04:49,347 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:04:49,433 - INFO - allennlp.training.trainer - Epoch duration: 0:00:48.452960\n",
            "2020-12-15 11:04:49,433 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:54\n",
            "2020-12-15 11:04:49,433 - INFO - allennlp.training.trainer - Epoch 15/19\n",
            "2020-12-15 11:04:49,433 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:04:49,433 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:04:49,434 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7107, mrr: 0.8619, ndcg: 0.4327, batch_loss: 0.0850, loss: 0.1011 ||: 100%|##########| 196/196 [00:35<00:00,  5.46it/s]\n",
            "2020-12-15 11:05:25,490 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:10<00:00,  8.54it/s]\n",
            "2020-12-15 11:05:36,419 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:05:36,420 - INFO - allennlp.training.tensorboard_writer - auc                |     0.711  |     0.650\n",
            "2020-12-15 11:05:36,420 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:05:36,421 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:05:36,422 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.862  |     0.846\n",
            "2020-12-15 11:05:36,423 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.433  |     0.421\n",
            "2020-12-15 11:05:36,424 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:05:36,509 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.075982\n",
            "2020-12-15 11:05:36,509 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:03:07\n",
            "2020-12-15 11:05:36,509 - INFO - allennlp.training.trainer - Epoch 16/19\n",
            "2020-12-15 11:05:36,509 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:05:36,510 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:05:36,510 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7125, mrr: 0.8614, ndcg: 0.4324, batch_loss: 0.0846, loss: 0.1011 ||: 100%|##########| 196/196 [00:38<00:00,  5.14it/s]\n",
            "2020-12-15 11:06:14,808 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:11<00:00,  8.23it/s]\n",
            "2020-12-15 11:06:26,156 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:06:26,157 - INFO - allennlp.training.tensorboard_writer - auc                |     0.713  |     0.650\n",
            "2020-12-15 11:06:26,157 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:06:26,158 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:06:26,159 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.861  |     0.846\n",
            "2020-12-15 11:06:26,160 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:06:26,160 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:06:26,254 - INFO - allennlp.training.trainer - Epoch duration: 0:00:49.744551\n",
            "2020-12-15 11:06:26,254 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:02:21\n",
            "2020-12-15 11:06:26,254 - INFO - allennlp.training.trainer - Epoch 17/19\n",
            "2020-12-15 11:06:26,254 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:06:26,254 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:06:26,255 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7105, mrr: 0.8612, ndcg: 0.4323, batch_loss: 0.0833, loss: 0.1012 ||: 100%|##########| 196/196 [00:36<00:00,  5.33it/s]\n",
            "2020-12-15 11:07:03,196 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:11<00:00,  8.39it/s]\n",
            "2020-12-15 11:07:14,330 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:07:14,330 - INFO - allennlp.training.tensorboard_writer - auc                |     0.711  |     0.650\n",
            "2020-12-15 11:07:14,331 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:07:14,332 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:07:14,332 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.861  |     0.846\n",
            "2020-12-15 11:07:14,333 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:07:14,333 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:07:14,421 - INFO - allennlp.training.trainer - Epoch duration: 0:00:48.166545\n",
            "2020-12-15 11:07:14,421 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:01:34\n",
            "2020-12-15 11:07:14,421 - INFO - allennlp.training.trainer - Epoch 18/19\n",
            "2020-12-15 11:07:14,421 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:07:14,421 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:07:14,422 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7106, mrr: 0.8613, ndcg: 0.4321, batch_loss: 0.0811, loss: 0.1012 ||: 100%|##########| 196/196 [00:37<00:00,  5.29it/s]\n",
            "2020-12-15 11:07:51,616 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:11<00:00,  7.99it/s]\n",
            "2020-12-15 11:08:03,305 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:08:03,306 - INFO - allennlp.training.tensorboard_writer - auc                |     0.711  |     0.650\n",
            "2020-12-15 11:08:03,307 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:08:03,307 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:08:03,308 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.861  |     0.846\n",
            "2020-12-15 11:08:03,309 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:08:03,310 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:08:03,396 - INFO - allennlp.training.trainer - Epoch duration: 0:00:48.974629\n",
            "2020-12-15 11:08:03,396 - INFO - allennlp.training.trainer - Estimated training time remaining: 0:00:47\n",
            "2020-12-15 11:08:03,396 - INFO - allennlp.training.trainer - Epoch 19/19\n",
            "2020-12-15 11:08:03,396 - INFO - allennlp.training.trainer - Worker 0 memory usage: 4.8G\n",
            "2020-12-15 11:08:03,396 - INFO - allennlp.training.trainer - GPU 0 memory usage: 690M\n",
            "2020-12-15 11:08:03,397 - INFO - allennlp.training.trainer - Training\n",
            "auc: 0.7093, mrr: 0.8604, ndcg: 0.4316, batch_loss: 0.0839, loss: 0.1013 ||: 100%|##########| 196/196 [00:36<00:00,  5.44it/s]\n",
            "2020-12-15 11:08:39,569 - INFO - allennlp.training.trainer - Validating\n",
            "auc: 0.6502, mrr: 0.8462, ndcg: 0.4205, batch_loss: 0.1244, loss: 0.1107 ||: 100%|##########| 93/93 [00:10<00:00,  8.48it/s]\n",
            "2020-12-15 11:08:50,583 - INFO - allennlp.training.tensorboard_writer -                        Training |  Validation\n",
            "2020-12-15 11:08:50,583 - INFO - allennlp.training.tensorboard_writer - auc                |     0.709  |     0.650\n",
            "2020-12-15 11:08:50,584 - INFO - allennlp.training.tensorboard_writer - gpu_0_memory_MB    |   689.753  |       N/A\n",
            "2020-12-15 11:08:50,584 - INFO - allennlp.training.tensorboard_writer - loss               |     0.101  |     0.111\n",
            "2020-12-15 11:08:50,585 - INFO - allennlp.training.tensorboard_writer - mrr                |     0.860  |     0.846\n",
            "2020-12-15 11:08:50,586 - INFO - allennlp.training.tensorboard_writer - ndcg               |     0.432  |     0.421\n",
            "2020-12-15 11:08:50,587 - INFO - allennlp.training.tensorboard_writer - worker_0_memory_MB |  4883.887  |       N/A\n",
            "2020-12-15 11:08:50,673 - INFO - allennlp.training.trainer - Epoch duration: 0:00:47.276692\n",
            "2020-12-15 11:08:50,673 - INFO - allennlp.training.checkpointer - loading best weights\n",
            "2020-12-15 11:08:50,688 - INFO - allennlp.common.util - Metrics: {\n",
            "  \"best_epoch\": 4,\n",
            "  \"peak_worker_0_memory_MB\": 4883.88671875,\n",
            "  \"peak_gpu_0_memory_MB\": 689.7529296875,\n",
            "  \"training_duration\": \"0:15:45.267457\",\n",
            "  \"training_start_epoch\": 0,\n",
            "  \"training_epochs\": 19,\n",
            "  \"epoch\": 19,\n",
            "  \"training_auc\": 0.7092898530698206,\n",
            "  \"training_mrr\": 0.860414981842041,\n",
            "  \"training_ndcg\": 0.43158242106437683,\n",
            "  \"training_loss\": 0.10132196925732555,\n",
            "  \"training_worker_0_memory_MB\": 4883.88671875,\n",
            "  \"training_gpu_0_memory_MB\": 689.7529296875,\n",
            "  \"validation_auc\": 0.650176368250144,\n",
            "  \"validation_mrr\": 0.8462393879890442,\n",
            "  \"validation_ndcg\": 0.42052674293518066,\n",
            "  \"validation_loss\": 0.11065674701365091,\n",
            "  \"best_validation_auc\": 0.6554928147885235,\n",
            "  \"best_validation_mrr\": 0.8462443351745605,\n",
            "  \"best_validation_ndcg\": 0.42056429386138916,\n",
            "  \"best_validation_loss\": 0.10878984189482145\n",
            "}\n",
            "2020-12-15 11:08:50,688 - INFO - allennlp.models.archival - archiving weights and vocabulary to result2/model.tar.gz\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhuqN1taK5w2"
      },
      "source": [
        "## Just for fun, Exploring futher"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XSPh0ItBK_6o"
      },
      "source": [
        "##Reading Comprehension\r\n",
        "Reading comprehension is the task of answering questions about a passage of text to show that the system understands the passage.\r\n",
        "\r\n",
        "Notice in the following experiments, I have give a passage to the model with a question, and the model is able to return me acceptable answer, which means our model understand what we say, Which is **AMAZZZZZING**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6M2NLiVLRj5"
      },
      "source": [
        "### Experiment 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIU60I7S5Z2Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ca52a5f-abea-4252-b21a-821d419a4b72"
      },
      "source": [
        "from allennlp.predictors.predictor import Predictor\r\n",
        "import allennlp_models.rc\r\n",
        "predictor = Predictor.from_path(\"https://storage.googleapis.com/allennlp-public-models/bidaf-elmo-model-2020.03.19.tar.gz\")\r\n",
        "ans = predictor.predict(\r\n",
        "  passage=\"The Matrix is a 1999 science fiction action film written and directed by The Wachowskis, starring Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano.\",\r\n",
        "  question=\"Who stars in The Matrix?\"\r\n",
        ")\r\n",
        "print('-------------------------------------------------------------------')\r\n",
        "print('Qestion :- Who stars in The Matrix')\r\n",
        "print(\"Answer Predicted :-\",ans['best_span_str'])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "downloading: 100%|##########| 418130723/418130723 [00:05<00:00, 82917561.21B/s]\n",
            "downloading: 100%|##########| 336/336 [00:00<00:00, 973263.91B/s]\n",
            "downloading: 100%|##########| 374434792/374434792 [00:04<00:00, 81881442.04B/s]\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:434: UserWarning: Setting attributes on ParameterList is not supported.\n",
            "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------\n",
            "Qestion :- Who stars in The Matrix\n",
            "Answer Predicted :- Keanu Reeves, Laurence Fishburne, Carrie-Anne Moss, Hugo Weaving, and Joe Pantoliano\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-tmAC-nL1-J"
      },
      "source": [
        "### Experiment 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSL2WJgVLG0g",
        "outputId": "ea31419b-5eb2-401b-bffa-1adf9dfed969"
      },
      "source": [
        "ans = predictor.predict(\r\n",
        "  passage=\"A reusable launch system (RLS, or reusable launch vehicle, RLV) is a launch system which is capable of launching a payload into space more than once. This contrasts with expendable launch systems, where each launch vehicle is launched once and then discarded. No completely reusable orbital launch system has ever been created. Two partially reusable launch systems were developed, the Space Shuttle and Falcon 9. The Space Shuttle was partially reusable: the orbiter (which included the Space Shuttle main engines and the Orbital Maneuvering System engines), and the two solid rocket boosters were reused after several months of refitting work for each launch. The external tank was discarded after each flight.\",\r\n",
        "  question=\"How many partially reusable launch systems were developed?\"\r\n",
        ")\r\n",
        "print('-------------------------------------------------------------------')\r\n",
        "print('Qestion :- How many partially reusable launch systems were developed?')\r\n",
        "print(\"Answer Predicted :-\",ans['best_span_str'])"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------\n",
            "Qestion :- How many partially reusable launch systems were developed?\n",
            "Answer Predicted :- Two\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWJu-8riMBqo"
      },
      "source": [
        "### Experiment 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bxGLdz0YL1Pn",
        "outputId": "a7ccc816-9639-46a5-a43e-7fcd4b2d4d5e"
      },
      "source": [
        "ans = predictor.predict(\r\n",
        "  passage=\"Robotics is an interdisciplinary branch of engineering and science that includes mechanical engineering, electrical engineering, computer science, and others. Robotics deals with the design, construction, operation, and use of robots, as well as computer systems for their control, sensory feedback, and information processing. These technologies are used to develop machines that can substitute for humans. Robots can be used in any situation and for any purpose, but today many are used in dangerous environments (including bomb detection and de-activation), manufacturing processes, or where humans cannot survive. Robots can take on any form but some are made to resemble humans in appearance. This is said to help in the acceptance of a robot in certain replicative behaviors usually performed by people. Such robots attempt to replicate walking, lifting, speech, cognition, and basically anything a human can do.\",\r\n",
        "  question=\"What do robots that resemble humans attempt to do?\"\r\n",
        ")\r\n",
        "print('-------------------------------------------------------------------')\r\n",
        "print('Qestion :- What do robots that resemble humans attempt to do?')\r\n",
        "print(\"Answer Predicted :-\",ans['best_span_str'])\r\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------\n",
            "Qestion :- What do robots that resemble humans attempt to do?\n",
            "Answer Predicted :- replicate walking, lifting, speech, cognition, and basically anything a human can\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lNvoB1F3MSTj"
      },
      "source": [
        "### Experiment 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cu3njgetMBGc",
        "outputId": "6fedb766-1147-4f62-c47d-46c2c8804a7b"
      },
      "source": [
        "ans = predictor.predict(\r\n",
        "  passage=\"Kerbal Space Program (KSP) is a space flight simulation video game developed and published by Squad for Microsoft Windows, OS X, Linux, PlayStation 4, Xbox One, with a Wii U version that was supposed to be released at a later date. The developers have stated that the gaming landscape has changed since that announcement and more details will be released soon. In the game, players direct a nascent space program, staffed and crewed by humanoid aliens known as \\\"Kerbals\\\". The game features a realistic orbital physics engine, allowing for various real-life orbital maneuvers such as Hohmann transfer orbits and bi-elliptic transfer orbits.\",\r\n",
        "  question=\"What does the physics engine allow for?\"\r\n",
        ")\r\n",
        "print('-------------------------------------------------------------------')\r\n",
        "print('Qestion :- What does the physics engine allow for?')\r\n",
        "print(\"Answer Predicted :-\",ans['best_span_str'])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "-------------------------------------------------------------------\n",
            "Qestion :- What does the physics engine allow for?\n",
            "Answer Predicted :- real-life orbital maneuvers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aJ24mwTyMGps"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}